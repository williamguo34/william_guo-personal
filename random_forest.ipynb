{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Fake_news_content_detection.csv')\n",
    "\n",
    "# Combine target columns into a single target variable\n",
    "target_columns = ['Barely-True', 'False', 'Half-True', 'Mostly-True', 'Not-Known', 'True']\n",
    "data['Target'] = data[target_columns].idxmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Drop rows with missing text data\n",
    "data = data.dropna(subset=['Text'])\n",
    "\n",
    "# Split data into features and target\n",
    "X = data['Text']  # Feature: Text column\n",
    "y = data['Target']  # Target: Newly created Target column\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Vectorize Text Data\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_df=0.7)\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train Random Forest Classifier\n",
    "model = RandomForestClassifier(n_estimators=300, max_depth=None, min_samples_split=5, min_samples_leaf=1, max_features='sqrt', random_state=42)\n",
    "model.fit(X_train_vec, y_train)\n",
    "\n",
    "# Make Predictions\n",
    "y_pred = model.predict(X_test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Set up the parameter grid for GridSearchCV\\nparam_grid = {\\n    \\'n_estimators\\': [100, 200, 300],\\n    \\'max_depth\\': [None, 10, 20],\\n    \\'min_samples_split\\': [2, 5],\\n    \\'min_samples_leaf\\': [1, 2],\\n    \\'max_features\\': [\\'auto\\', \\'sqrt\\', \\'log2\\']\\n}\\n\\n# Create the base model for GridSearchCV\\nrf = RandomForestClassifier(random_state=42)\\n\\n# Use GridSearchCV to find the best parameters\\ngrid_search = GridSearchCV(estimator=rf, param_grid=param_grid,\\n                          cv=5, n_jobs=-1, verbose=2, scoring=\\'accuracy\\')\\ngrid_search.fit(X_train_vec, y_train)\\n\\n# Print the best parameters\\nprint(\"Best parameters found: \", grid_search.best_params_)\\n\\n# Use the best model to make predictions\\nmodel = grid_search.best_estimator_\\ny_pred = model.predict(X_test_vec)'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Set up the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# Create the base model for GridSearchCV\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Use GridSearchCV to find the best parameters\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid,\n",
    "                          cv=5, n_jobs=-1, verbose=2, scoring='accuracy')\n",
    "grid_search.fit(X_train_vec, y_train)\n",
    "\n",
    "# Print the best parameters\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "\n",
    "# Use the best model to make predictions\n",
    "model = grid_search.best_estimator_\n",
    "y_pred = model.predict(X_test_vec)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.26\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " Barely-True       0.30      0.15      0.19       331\n",
      "       False       0.23      0.42      0.30       399\n",
      "   Half-True       0.25      0.26      0.26       423\n",
      " Mostly-True       0.26      0.34      0.30       392\n",
      "   Not-Known       0.55      0.07      0.12       168\n",
      "        True       0.29      0.18      0.22       335\n",
      "\n",
      "    accuracy                           0.26      2048\n",
      "   macro avg       0.31      0.23      0.23      2048\n",
      "weighted avg       0.29      0.26      0.25      2048\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Evaluate the Model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Actual    Predicted  \\\n",
      "1829        False  Barely-True   \n",
      "713         False  Mostly-True   \n",
      "52          False        False   \n",
      "1582    Half-True  Mostly-True   \n",
      "856   Mostly-True  Mostly-True   \n",
      "782          True        False   \n",
      "1633    Half-True        False   \n",
      "1432  Barely-True         True   \n",
      "1690  Mostly-True  Mostly-True   \n",
      "1341  Mostly-True  Mostly-True   \n",
      "1811  Mostly-True  Barely-True   \n",
      "1172        False  Barely-True   \n",
      "706         False        False   \n",
      "815          True         True   \n",
      "453   Mostly-True        False   \n",
      "1846        False    Half-True   \n",
      "1227    Not-Known        False   \n",
      "1613    Half-True    Half-True   \n",
      "1450    Not-Known        False   \n",
      "736   Mostly-True    Half-True   \n",
      "\n",
      "                                                   Text  \n",
      "1829  Obamacare means that for up to 20 million Amer...  \n",
      "713   I dont think the argument can be credibly made...  \n",
      "52    Says government is a barrier to innovation and...  \n",
      "1582  Today, when people retire in Galveston County,...  \n",
      "856   Two-thirds of the people who receive the minim...  \n",
      "782   Says state Rep. Diana Maldonado of Round Rock ...  \n",
      "1633  I had five of my citizens that were killed las...  \n",
      "1432  Says Democratic opponent is too Republican to ...  \n",
      "1690  Says cities save an estimated $38 in dental co...  \n",
      "1341  A test last month at the MAX station at 162nd ...  \n",
      "1811  Says at the state level were spending more on ...  \n",
      "1172  John Cornyn backed his pal David Dewhurst for ...  \n",
      "706   Says Hillary Clinton is proposing destroying M...  \n",
      "815   Gross income tax receipts are exceeding the Ad...  \n",
      "453   Says he never told anyone he hated the U.S. Se...  \n",
      "1846  Says Obama called Israel \"a constant sore\" tha...  \n",
      "1227  The Republicans have never done anything reall...  \n",
      "1613  The RESTORE Act started as an effort to dedica...  \n",
      "1450  Austin is effectively imposing a ban on barbec...  \n",
      "736   The federal government only ordered BP to pay ...  \n"
     ]
    }
   ],
   "source": [
    "# Display Sample Predictions\n",
    "sample_data = X_test.reset_index(drop=True)\n",
    "predictions_df = pd.DataFrame({'Actual': y_test.reset_index(drop=True), 'Predicted': y_pred})\n",
    "predictions_df['Text'] = sample_data\n",
    "print(predictions_df.sample(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model and vectorizer\n",
    "#joblib.dump(model, 'random_forest_model.joblib')\n",
    "#joblib.dump(vectorizer, 'tfidf_vectorizer.joblib')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ipykernel_py3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
