{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Fake_news_content_detection.csv')\n",
    "\n",
    "# Combine target columns into a single target variable\n",
    "target_columns = ['Barely-True', 'False', 'Half-True', 'Mostly-True', 'Not-Known', 'True']\n",
    "data['Target'] = data[target_columns].idxmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Drop rows with missing text data\n",
    "data = data.dropna(subset=['Text'])\n",
    "\n",
    "# Split data into features and target\n",
    "X = data['Text']  # Feature: Text column\n",
    "y = data['Target']  # Target: Newly created Target column\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Vectorize Text Data\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_df=0.7)\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train Random Forest Classifier\n",
    "model = RandomForestClassifier(n_estimators=300, max_depth=None, min_samples_split=5, min_samples_leaf=1, max_features='sqrt', random_state=42)\n",
    "model.fit(X_train_vec, y_train)\n",
    "\n",
    "# Make Predictions\n",
    "y_pred = model.predict(X_test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Set up the parameter grid for GridSearchCV\\nparam_grid = {\\n    \\'n_estimators\\': [100, 200, 300],\\n    \\'max_depth\\': [None, 10, 20],\\n    \\'min_samples_split\\': [2, 5],\\n    \\'min_samples_leaf\\': [1, 2],\\n    \\'max_features\\': [\\'sqrt\\', \\'log2\\']\\n}\\n\\n# Create the base model for GridSearchCV\\nrf = RandomForestClassifier(random_state=42)\\n\\n# Use GridSearchCV to find the best parameters\\ngrid_search = GridSearchCV(estimator=rf, param_grid=param_grid,\\n                          cv=5, n_jobs=-1, verbose=2, scoring=\\'accuracy\\')\\ngrid_search.fit(X_train_vec, y_train)\\n\\n# Print the best parameters\\nprint(\"Best parameters found: \", grid_search.best_params_)\\n\\n# Use the best model to make predictions\\nmodel = grid_search.best_estimator_\\ny_pred = model.predict(X_test_vec)'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Set up the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# Create the base model for GridSearchCV\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Use GridSearchCV to find the best parameters\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid,\n",
    "                          cv=5, n_jobs=-1, verbose=2, scoring='accuracy')\n",
    "grid_search.fit(X_train_vec, y_train)\n",
    "\n",
    "# Print the best parameters\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "\n",
    "# Use the best model to make predictions\n",
    "model = grid_search.best_estimator_\n",
    "y_pred = model.predict(X_test_vec)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.26\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " Barely-True       0.30      0.15      0.19       331\n",
      "       False       0.23      0.42      0.30       399\n",
      "   Half-True       0.25      0.26      0.26       423\n",
      " Mostly-True       0.26      0.34      0.30       392\n",
      "   Not-Known       0.55      0.07      0.12       168\n",
      "        True       0.29      0.18      0.22       335\n",
      "\n",
      "    accuracy                           0.26      2048\n",
      "   macro avg       0.31      0.23      0.23      2048\n",
      "weighted avg       0.29      0.26      0.25      2048\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Evaluate the Model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Actual    Predicted  \\\n",
      "1371  Barely-True        False   \n",
      "240   Mostly-True    Half-True   \n",
      "2045  Mostly-True    Half-True   \n",
      "941         False        False   \n",
      "1205    Half-True        False   \n",
      "1243  Barely-True  Mostly-True   \n",
      "1765    Half-True        False   \n",
      "650         False  Barely-True   \n",
      "1011  Barely-True  Mostly-True   \n",
      "1373    Half-True    Half-True   \n",
      "\n",
      "                                                   Text  \n",
      "1371  A Texas law will repatriate $1 billion of gold...  \n",
      "240   Says Donald Trump said he intends to open up a...  \n",
      "2045  Says that under Rick Perrys plan, Texas has cu...  \n",
      "941     Were the most highly taxed nation in the world.  \n",
      "1205  I have won more elections than any chairman si...  \n",
      "1243                   We are winning the popular vote.  \n",
      "1765  President Barack Obama's \"initial response whe...  \n",
      "650   Says that Sherrod Brown voted to cut Medicare ...  \n",
      "1011  In 2005 and 2007, Joe Straus received a 100 pe...  \n",
      "1373  Says Rep. Maxine Waters, D-Calif., only needs ...  \n"
     ]
    }
   ],
   "source": [
    "# Display Sample Predictions\n",
    "sample_data = X_test.reset_index(drop=True)\n",
    "predictions_df = pd.DataFrame({'Actual': y_test.reset_index(drop=True), 'Predicted': y_pred})\n",
    "predictions_df['Text'] = sample_data\n",
    "print(predictions_df.sample(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tfidf_vectorizer.joblib']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model and vectorizer\n",
    "joblib.dump(model, 'random_forest_model.joblib')\n",
    "joblib.dump(vectorizer, 'tfidf_vectorizer.joblib')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ipykernel_py3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
